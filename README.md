# Proyecto Final - Infraestructuras Paralelas y Distribuidas
## AnÃ¡lisis de CorrelaciÃ³n entre Noticias EconÃ³micas e Ãndice COLCAP

### ğŸ“‹ DescripciÃ³n del Proyecto

Este proyecto implementa un sistema distribuido y escalable para procesar y analizar informaciÃ³n noticiosa de fuentes abiertas (simulando Common Crawl) con el fin de identificar correlaciones entre eventos mediÃ¡ticos econÃ³micos y el comportamiento del Ã­ndice COLCAP de la Bolsa de Valores de Colombia.

El sistema estÃ¡ construido con arquitectura de microservicios, desplegado en Kubernetes, y demuestra la aplicaciÃ³n prÃ¡ctica de conceptos de:
- âœ… ComputaciÃ³n paralela y distribuida
- âœ… OrquestaciÃ³n de contenedores
- âœ… Procesamiento distribuido de datos
- âœ… Escalabilidad horizontal
- âœ… Tolerancia a fallos

---

## ğŸ—ï¸ Arquitectura del Sistema

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    KUBERNETES CLUSTER                        â”‚
â”‚                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”‚
â”‚  â”‚   Plotter    â”‚â—„â”€â”€â”€â”€â”€â”¤  Aggregator  â”‚                    â”‚
â”‚  â”‚  (Frontend)  â”‚      â”‚   (Backend)  â”‚                    â”‚
â”‚  â”‚  Replicas: 2 â”‚      â”‚  Replicas: 2 â”‚                    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜                    â”‚
â”‚         â–²                       â”‚                            â”‚
â”‚         â”‚                       â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚
â”‚         â”‚                       â–¼             â–¼             â”‚
â”‚    [LoadBalancer]        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚         â”‚                â”‚  COLCAP  â”‚  â”‚CommonCrawlâ”‚       â”‚
â”‚         â”‚                â”‚ Fetcher  â”‚  â”‚  Workers  â”‚       â”‚
â”‚         â”‚                â”‚Replicas:2â”‚  â”‚Replicas: 5â”‚       â”‚
â”‚         â”‚                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜       â”‚
â”‚         â”‚                                    â”‚              â”‚
â”‚         â”‚                              â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”       â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤   Redis   â”‚       â”‚
â”‚                                        â”‚  (Cache)  â”‚       â”‚
â”‚                                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Componentes del Sistema

#### 1. **COLCAP Fetcher** (2 rÃ©plicas)
- Obtiene datos del Ã­ndice COLCAP
- Genera datos simulados realistas basados en patrones histÃ³ricos
- Endpoints:
  - `GET /health` - Health check
  - `GET /colcap?start_date=YYYY-MM-DD&end_date=YYYY-MM-DD` - Obtener datos histÃ³ricos
  - `GET /colcap/latest` - Obtener valor mÃ¡s reciente

#### 2. **CommonCrawl Workers** (5 rÃ©plicas)
- Procesan noticias econÃ³micas de forma distribuida
- Implementan anÃ¡lisis de contenido y extracciÃ³n de keywords
- Utilizan Redis para cachÃ© y distribuciÃ³n de trabajo
- Endpoints:
  - `GET /health` - Health check
  - `GET /process?year=YYYY&month=MM` - Procesar mes especÃ­fico
  - `POST /process/batch` - Procesamiento por lotes
  - `GET /stats` - EstadÃ­sticas del worker

#### 3. **Aggregator** (2 rÃ©plicas)
- Agrega datos de mÃºltiples fuentes
- Calcula correlaciones estadÃ­sticas
- Implementa procesamiento paralelo con ThreadPoolExecutor
- Endpoints:
  - `GET /health` - Health check
  - `GET /aggregate?start_date=YYYY-MM-DD&end_date=YYYY-MM-DD&parallel=true` - AgregaciÃ³n completa
  - `GET /correlation` - Solo anÃ¡lisis de correlaciÃ³n

#### 4. **Plotter** (2 rÃ©plicas)
- Genera visualizaciones de los datos
- Crea mÃºltiples tipos de grÃ¡ficos
- Expuesto pÃºblicamente mediante LoadBalancer
- Endpoints:
  - `GET /health` - Health check
  - `GET /plot?type=correlation&format=png` - Generar grÃ¡fico especÃ­fico
    - Tipos: `correlation`, `scatter`, `heatmap`
    - Formatos: `png`, `base64`
  - `GET /plot/all` - Generar todos los grÃ¡ficos

#### 5. **Redis** (1 rÃ©plica)
- Sistema de cachÃ© distribuido
- Almacena resultados de procesamiento
- TTL de 1 hora para datos cacheados

---

## ğŸš€ Despliegue del Sistema

### Prerrequisitos

- Docker Desktop con Kubernetes habilitado
- kubectl configurado
- Al menos 4GB de RAM disponible

### Paso 1: Construir las imÃ¡genes Docker

```powershell
# Construir todas las imÃ¡genes
docker build -t colcap-fetcher:latest ./colcap-fetcher
docker build -t commoncrawl-worker:latest ./commoncrawl-worker
docker build -t aggregator:latest ./aggregator
docker build -t plotter:latest ./plotter
```

### Paso 2: Desplegar en Kubernetes

```powershell
# Aplicar ConfigMap y Redis primero
kubectl apply -f k8s/redis-deployment.yaml

# Desplegar servicios backend
kubectl apply -f k8s/colcap-deployment.yaml
kubectl apply -f k8s/commoncrawl-deployment.yaml
kubectl apply -f k8s/aggregator-deployment.yaml

# Desplegar frontend
kubectl apply -f k8s/plotter-deployment.yaml
```

### Paso 3: Verificar el despliegue

```powershell
# Ver todos los pods
kubectl get pods

# Ver servicios
kubectl get services

# Ver logs de un pod especÃ­fico
kubectl logs -f <pod-name>

# Verificar health de todos los servicios
kubectl get pods -o wide
```

### Paso 4: Acceder al sistema

```powershell
# Obtener la URL del servicio plotter
kubectl get service plotter

# Si estÃ¡ en LoadBalancer, usar la IP externa
# Si estÃ¡ en NodePort, usar: http://localhost:<NodePort>

# Para desarrollo local (port-forward)
kubectl port-forward service/plotter 8080:80
# Acceder en: http://localhost:8080
```

---

## ğŸ“Š Uso del Sistema

### Ejemplo 1: Obtener grÃ¡fico de correlaciÃ³n

```bash
curl "http://localhost:8080/plot?type=correlation&start_date=2024-10-01&end_date=2024-12-31" > correlation.png
```

### Ejemplo 2: Obtener todos los grÃ¡ficos en base64

```bash
curl "http://localhost:8080/plot/all?start_date=2024-10-01&end_date=2024-12-31"
```

### Ejemplo 3: Obtener solo anÃ¡lisis de correlaciÃ³n

```bash
curl "http://localhost:8080/../aggregator:5000/correlation?start_date=2024-10-01&end_date=2024-12-31"
```

### Ejemplo 4: Consultar health checks

```bash
# Health de todos los servicios
kubectl get pods | grep Running

# Health check individual
kubectl exec -it <pod-name> -- curl localhost:5000/health
```

---

## ğŸ”§ ConfiguraciÃ³n

### Variables de Entorno (ConfigMap)

```yaml
REDIS_HOST: "redis"
REDIS_PORT: "6379"
LOG_LEVEL: "INFO"
```

### Recursos por Servicio

| Servicio | CPU Request | CPU Limit | Memory Request | Memory Limit | RÃ©plicas |
|----------|-------------|-----------|----------------|--------------|----------|
| COLCAP Fetcher | 100m | 300m | 128Mi | 256Mi | 2 |
| CommonCrawl Worker | 200m | 500m | 256Mi | 512Mi | 5 |
| Aggregator | 200m | 500m | 256Mi | 512Mi | 2 |
| Plotter | 200m | 500m | 256Mi | 512Mi | 2 |
| Redis | 100m | 200m | 128Mi | 256Mi | 1 |

---

## ğŸ“ˆ CaracterÃ­sticas de ParalelizaciÃ³n

### 1. **Procesamiento Paralelo en Aggregator**
- Utiliza `ThreadPoolExecutor` con 3 workers
- Procesa mÃºltiples meses simultÃ¡neamente
- Reduce tiempo de procesamiento en ~60%

### 2. **DistribuciÃ³n de Carga con Kubernetes**
- 5 rÃ©plicas de CommonCrawl Workers
- Service balanceo automÃ¡tico de carga
- Escalabilidad horizontal mediante `kubectl scale`

### 3. **CachÃ© Distribuido con Redis**
- Evita procesamiento redundante
- TTL configurable (default: 1 hora)
- Mejora tiempos de respuesta en ~80%

### 4. **Health Checks y Auto-recuperaciÃ³n**
- Liveness probes cada 10 segundos
- Readiness probes cada 5 segundos
- Auto-restart en caso de fallo

---

## ğŸ§ª Pruebas y ValidaciÃ³n

### Pruebas de Carga

```powershell
# Escalar workers para mayor capacidad
kubectl scale deployment commoncrawl --replicas=10

# Monitorear recursos
kubectl top pods
kubectl top nodes

# Ver mÃ©tricas de Redis
kubectl exec -it redis-<pod-id> -- redis-cli INFO stats
```

### Pruebas de Tolerancia a Fallos

```powershell
# Eliminar un pod y ver auto-recuperaciÃ³n
kubectl delete pod <pod-name>

# Ver que Kubernetes crea uno nuevo automÃ¡ticamente
kubectl get pods -w
```

### Pruebas de Escalabilidad

```bash
# Benchmark con mÃºltiples requests simultÃ¡neas
for i in {1..50}; do
  curl "http://localhost:8080/plot?type=correlation" > /dev/null 2>&1 &
done
```

---

## ğŸ“Š AnÃ¡lisis de CorrelaciÃ³n

El sistema calcula:

1. **Coeficiente de CorrelaciÃ³n de Pearson**: Mide la relaciÃ³n lineal entre volumen de noticias y COLCAP
2. **InterpretaciÃ³n AutomÃ¡tica**:
   - |r| â‰¥ 0.7: CorrelaciÃ³n fuerte
   - 0.4 â‰¤ |r| < 0.7: CorrelaciÃ³n moderada
   - 0.2 â‰¤ |r| < 0.4: CorrelaciÃ³n dÃ©bil
   - |r| < 0.2: CorrelaciÃ³n muy dÃ©bil

3. **MÃ©tricas Adicionales**:
   - Volatilidad del COLCAP
   - Promedios mÃ³viles
   - AnÃ¡lisis de keywords mÃ¡s frecuentes
   - DistribuciÃ³n temporal

---

## ğŸ› ï¸ Desarrollo y Debugging

### Ver logs en tiempo real

```powershell
# Logs de todos los pods de un deployment
kubectl logs -f deployment/commoncrawl

# Logs de un pod especÃ­fico
kubectl logs -f <pod-name>

# Logs de contenedor especÃ­fico en pod multi-contenedor
kubectl logs -f <pod-name> -c <container-name>
```

### Ejecutar comandos dentro de pods

```powershell
# Shell interactivo
kubectl exec -it <pod-name> -- /bin/bash

# Comando Ãºnico
kubectl exec <pod-name> -- curl localhost:5000/health
```

### Debugging de networking

```powershell
# Ver endpoints de un servicio
kubectl get endpoints <service-name>

# Describir servicio
kubectl describe service <service-name>

# Test de conectividad desde un pod
kubectl exec -it <pod-name> -- curl http://colcap:5000/health
```

---

## ğŸ“ Notas Importantes

### Datos Simulados

El sistema actualmente utiliza datos simulados realistas para:
- **COLCAP**: Generados con tendencias y volatilidad realista
- **Noticias**: Simuladas con conteo variable y keywords econÃ³micas

Para usar datos reales:
1. Implementar scraping del sitio de la BVC para COLCAP
2. Integrar con API real de Common Crawl
3. Agregar procesamiento NLP para anÃ¡lisis de contenido

### Limitaciones

- Redis no tiene volumen persistente (datos se pierden al reiniciar)
- Procesamiento limitado a 100 puntos de datos por respuesta
- Cache TTL fijo de 1 hora

### Mejoras Futuras

1. Implementar PersistentVolumes para Redis
2. Agregar autoscaling basado en mÃ©tricas (HPA)
3. Implementar circuit breaker pattern
4. Agregar monitoring con Prometheus + Grafana
5. Implementar CI/CD con GitHub Actions
6. Agregar tests unitarios y de integraciÃ³n

---

## ğŸ‘¥ Autores

**Universidad del Valle**  
**Curso**: Infraestructuras Paralelas y Distribuidas  
**AÃ±o**: 2025-II

---

## ğŸ“š Referencias

- [Common Crawl Foundation](https://commoncrawl.org)
- [Kubernetes Documentation](https://kubernetes.io/docs)
- [Docker Documentation](https://docs.docker.com)
- [Bolsa de Valores de Colombia](https://www.bvc.com.co)

---

## ğŸ“„ Licencia

Este proyecto es desarrollado con fines acadÃ©micos para el curso de Infraestructuras Paralelas y Distribuidas.
